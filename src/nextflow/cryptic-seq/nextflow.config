includeConfig 'pipeline.env'

manifest {
    name = 'cryptic-seq'
    author = 'Tome Biosciences'
    description = 'Cryptic-seq Pipeline'
    version = '1.0.0' // NB: must be in sync with /pipeline.env
    nextflowVersion = '>=22.04.0' // DSL2 is the default starting here
}

plugins {
    id 'nf-validation@1.1.4' // NB: Seqera Platform 24.2.0 does not play nice with nf-schema@2.0 yet.
}

params {
    // if true, show the help message and exit
    help = false
    // whether to run the version of the pipeline that uses
    // the wrapper around the snakemake workflow - primarily
    // for regression testing
    snakemake = false
    // options for executing with metadata from Benchling
    ctb_id = null
    genomes_json = null
    default_genome = null
    // options for executing with a metasheet
    metasheet = null
    // options to identify local inputs given a metasheet
    fastq_dir = null
    fastq_name_pattern = null
    attachment_sites = "${baseDir}/attachment-sites.json"
    // optional semicolon-separated list of default attachment site(s)
    default_attachment_site = null
    references_dir = null
    references_json = null
    default_reference = null
    // reference to use for searching for exact site matches during annotation step
    annotation_reference = null
    // whether to verify that reference and FASTQ files exist
    verify_files = false
    // output prefix - defaults to metasheet.simpleName
    prefix = null
    // dir where outputs should be linked/uploaded - defaults to launchDir/runID,
    // where runID is either the ctb_id or the metasheet filename
    output_dir = null
    // global snakemake config yaml
    global_config = null
    // option to specify the number of reads per chunk, to parallelize trimming of FASTQ files -
    // when set, FASTQ files will be split prior to the `fastq_to_ubam` step and merged to a
    // single uBAM prior to the alignment step
    fastq_chunk_size = null
    // parameters that can also be set in the global config when running
    // the snakemake workflow
    trim_Tn5 = false  // TODO: rename to `trim_Tn5_r1`
    trim_Tn5_max_mismatches = 1
    trim_att_max_mismatches = 4
    read_structure_r1 = '11M+T'
    read_structure_r2 = '+T'
    umi_from_read_name = false
    // other global parameters
    trim_Tn5_r2 = true
    trim_Tn5_r2_min_score = 12  // TODO: too low?
    trim_Tn5_r2_min_match_length = 18
    trim_Tn5_r2_min_keep_length = null
    keep_full_sites = false
    // sequence of r2 adapter to trim
    trim_adapter_r2 = null
    trim_adapter_r2_min_score = null  // TODO: too low?
    trim_adapter_r2_min_match_length = null
    trim_adapter_r2_min_keep_length = 25

    // Docker images
    docker_image_version = "${PIPELINE_VERSION}"
    docker_image_repo = "${ECR_REPO_ROOT}"
    fastqc_image = "${docker_image_repo}/tbchasin-fastqc:${docker_image_version}"
    multiqc_image = "${docker_image_repo}/tbchasin-multiqc:${docker_image_version}"
    picard_image = "${docker_image_repo}/tbchasin-picard:${docker_image_version}"
    fgbio_image = "${docker_image_repo}/tbchasin-fgbio:${docker_image_version}"
    tools_image = "${docker_image_repo}/tbchasin-tools:${docker_image_version}"
    // Monolothic image for use with cryptic-seq pipeline
    snakemake_cryptic_seq_image = "${docker_image_repo}/tbchasin-snakemake:${docker_image_version}"

    // Default and max resources specified as 'cpus;memory;disk;time'
    // Processes only need to specify requirements (within ext) if they are above default levels
    default_resources = '1;4.GB;100.GB;1.h'
    max_resources = '16;64.GB;1.TB;4.h'

    // Scale resources after this attempt, to deal with failures that are
    // due to insufficient resources. Set to `null` to never scale.
    scale_after_attempt = 1

    // nf-validation configuration
    validationSchemaIgnoreParams = [
        // Ignore params tied to pipeline configuration that should not change run-to-run
        "docker_image_version",
        "docker_image_repo",
        "fastqc_image",
        "multiqc_image",
        "picard_image",
        "fgbio_image",
        "tools_image",
        "snakemake_cryptic_seq_image",

        // NB: ignore attachment_sites param for "nf-core schema" tool which wants a default set in
        // the schema.json. We instead want a default to refer to the attachment sites committed in
        // this repo in $baseDir.
        "attachment_sites"

    ].join(",")
}

process {
    // publishDir for per-sample processes
    publishDir = { get_publish_dir(params, task.process, launchDir, meta.id) }

    // publishDir for aggregate processes
    withLabel: global {
        publishDir = { get_publish_dir(params, task.process, launchDir) }
    }

    // container configuration for native workflow processes
    withLabel: fastqc {
        container = "${params.fastqc_image}"
    }
    withLabel: multiqc {
        container = "${params.multiqc_image}"
    }
    withLabel: picard {
        container = "${params.picard_image}"
    }
    withLabel: fgbio {
        container = "${params.fgbio_image}"
    }
    withLabel: tools {
        container = "${params.tools_image}"
    }

    // publishDir and container for wrapped snakemake pipeline
    withName: snakemake_pipeline {
        publishDir = { "${params.output_dir ?: workflow.launchDir}/${prefix}" }
        container = "${params.snakemake_cryptic_seq_image}"
    }
    // resource allocations scaled by retry attempt
    cpus = {
        calc_resource(
            'cpus',
            string_or_null(task.ext.cpus),
            "${params.default_resources}",
            "${params.max_resources}",
            task.attempt
        )
    }
    memory = {
        calc_resource(
            'memory',
            string_or_null(task.ext.memory),
            "${params.default_resources}",
            "${params.max_resources}",
            task.attempt
        )
    }
    disk = {
        calc_resource(
            'disk',
            string_or_null(task.ext.disk),
            "${params.default_resources}",
            "${params.max_resources}",
            task.attempt
        )
    }
    time = {
        calc_resource(
            'time',
            string_or_null(task.ext.time),
            "${params.default_resources}",
            "${params.max_resources}",
            task.attempt
        )
    }
}

profiles {
    local {
        docker {
            enabled = true
        }

        params {
            verify_files = true
        }

        process {
            cache = 'lenient'
            executor = 'local'
            errorStrategy = 'retry'
            maxRetries = 2
            // TODO: this requires nextflow 24.04.0, which is not yet available in bioconda.
            // This will replace params.max_resources.
            // resourceLimits = [ cpus: 16, memory: 64.GB, disk: 1.TB, time: 4.h ]
        }
    }

    // Use this profile when running on MacOS under Rosetta emulation.
    rosetta {
        docker {
            platform = 'linux/amd64'
        }
    }

    // use this profile when running on linux
    // alteratively, configure docker on linux so that it does not require running as root:
    // https://docs.docker.com/engine/install/linux-postinstall/
    linux {
        docker {
            runOptions = '--user root'
        }
    }

    snakemake {
        params {
            snakemake = true
            // reset these to null here - the defaults will come from the global config
            trim_Tn5 = null
            trim_Tn5_max_mismatches = null
            trim_att_max_mismatches = null
            read_structure_r1 = null
            read_structure_r2 = null
            umi_from_read_name = null
        }
    }

    aws_seqera {
        process {
            errorStrategy = 'retry'
            maxRetries = 2
        }
    }
}

includeConfig 'tests/nextflow.config'

def get_publish_dir(params, processName, launchDir, sampleName = null) {
    def outputDir = params.output_dir
    if (outputDir == null) {
        def name = params.ctb_id ?: params.metasheet.replaceAll(/^(?:.*\/)?([^.]+).*/, '$1')
        outputDir = "${launchDir}/${name}"
    }
    if (sampleName != null) {
        outputDir = "${outputDir}/${sampleName}"
    }
    def sepIdx = processName.lastIndexOf(':')
    if (sepIdx >= 0) {
        processName = processName.substring(sepIdx + 1)
    }
    outputDir = "${outputDir}/${processName}"
    return outputDir
}

def string_or_null(value) {
    if (value == null) {
        return null
    } else {
        return "${value}"
    }
}

def calc_resource(
    String type, String base_value, String default_values, String max_values, Integer attempt
) {
    def default_array = default_values.split(';')
    def max_array = max_values.split(';')
    def value = null
    def max_value = null
    if (type == 'cpus') {
        value = (base_value ?: default_array[0]) as Integer
        max_value = max_array[0] as Integer
    } else if (type == 'memory') {
        value = (base_value ?: default_array[1]) as nextflow.util.MemoryUnit
        max_value = max_array[1] as nextflow.util.MemoryUnit
    } else if (type == 'disk') {
        value = (base_value ?: default_array[2]) as nextflow.util.MemoryUnit
        max_value = max_array[2] as nextflow.util.MemoryUnit
    } else if (type == 'time') {
        value = (base_value ?: default_array[3]) as nextflow.util.Duration
        max_value = max_array[3] as nextflow.util.Duration
    } else {
        exit 1, "Unknown resource type ${type} passed to calc_resource"
    }
    // Increase resource allocation after the first attempt, with the
    // intent to resolve failures due to insufficient resources.
    if (params.scale_after_attempt == null || attempt <= params.scale_after_attempt) {
        attempt = 1
    } else {
        attempt = attempt - params.scale_after_attempt + 1
    }
    return [value * attempt, max_value].min()
}